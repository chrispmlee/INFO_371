{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4: Build your own spam filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use smaller dataset to play with\n",
    "emailsplit = emails.copy()\n",
    "# emailsplit = emailsplit.loc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# words are already lemmatized, so we just remove punctuation\n",
    "emailsplit['text'] = emailsplit['text'].apply(lambda x: re.sub(r'[^\\w\\s]','',x)) # remove punctuation with regex\n",
    "\n",
    "# create cached object of stopwords to improve speed\n",
    "cachedStopwords = set(stopwords.words('english'))\n",
    "\n",
    "# remove stop words\n",
    "emailsplit['text'] = emailsplit.apply(lambda x: [item for item in x if item not in cachedStopwords])\n",
    "emailsplit['text'] = emailsplit['text'].str[8:] # remove \"subject\" from beginning of each email\n",
    "\n",
    "# remove numbers (alternatively, could convert to a single constant like a punctuation symbol to preserve some info)\n",
    "# emailsplit['text'] = emailsplit['text'].apply(lambda x: [item for item in x if item not in set())])\n",
    "\n",
    "#========================================\n",
    "# NOTES:\n",
    "# create one preprocessing function where we can choose what processing to do. Easier to check how it affects results.\n",
    "# does feature_extraction already do the above? may be redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bag of words and tf-idf sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "corpus = [] # list of email content, where each item in list is an email\n",
    "for i in range(len(emailsplit['text'])):\n",
    "    corpus.append(emailsplit.loc[i]['text'])\n",
    "    \n",
    "vectorizer = CountVectorizer() # create vectorizer\n",
    "\n",
    "wordmatrix = vectorizer.fit_transform(corpus) # sparse matrix where each value ij is how many times the word j occurs in email i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF (term frequency-inverse document frequency), a weighting scheme for words.\n",
    "# The weight increases when a word occurs many times in a small number of documents, leading to increased discriminatory power of the word. \n",
    "# The weight decreases when the word occurrs infrequently, or occurs in a large number of documents. \n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(wordmatrix) # create transformer based on vocab in train set\n",
    "tfidf = tfidf_transformer.transform(wordmatrix) # calculate tf-idf of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add extra variables\n",
    "\n",
    "# from scipy.sparse import hstack\n",
    "\n",
    "# # # punctuation count\n",
    "# # punct = set(string.punctuation)\n",
    "# # count_punct = lambda l1: sum([1 for x in l1 if x in punct])\n",
    "# # emailsplit = emailsplit.assign(punct = emails['text'].apply(count_punct))\n",
    "\n",
    "# # # message length\n",
    "# # emailsplit = emailsplit.assign(length = emails['text'].apply(len))\n",
    "\n",
    "# # count dollar sign punctuation\n",
    "# count_dollar = lambda l1: sum([1 for x in l1 if x in set('$')])\n",
    "# emailsplit = emailsplit.assign(dollar = emails['text'].apply(count_dollar))\n",
    "\n",
    "# tfidf_ex = hstack((tfidf ,np.array(emailsplit[['dollar']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_ex = tfidf_ex.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ex, emailsplit['spam'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB\n",
    "# Tuning n_estimators\n",
    "alphas = np.array([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "model3 = MultinomialNB()\n",
    "grid3 = GridSearchCV(estimator=model3, param_grid=dict(alpha=alphas), return_train_score=True)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(grid3.best_score_)\n",
    "print(grid3.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860565370410874"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "start_time1 = time.time()\n",
    "\n",
    "clf1 = MultinomialNB(random_state=0)\n",
    "# train model\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "time1 = str(round(time.time() - start_time1, 2))\n",
    "print(time1 + \" seconds\")\n",
    "\n",
    "cross_val_score(clf1, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900964295022153\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-69146f899a0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgridcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgridcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgridcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'n_estimators'"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# Tuning n_estimators\n",
    "grid2 = [{'C': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "         'tol': [0.0001, 0.001, 0.01, 0.1, 1.0]}]\n",
    "model2 = LinearSVC()\n",
    "gridcv2 = GridSearchCV(estimator=model2, param_grid=grid2, return_train_score=True)\n",
    "gridcv2.fit(X_train, y_train)\n",
    "print(gridcv2.best_score_)\n",
    "print(gridcv2.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929639868665673"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "start_time2 = time.time()\n",
    "\n",
    "clf2 = LinearSVC(random_state=0)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "time2 = str(round(time.time() - start_time2, 2))\n",
    "print(time2 + \" seconds\")\n",
    "\n",
    "# cross validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(clf2, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713317696116758\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Tuning for n_estimators\n",
    "# n_estimators = np.array(np.arange(50,70,1)) # the optimal parameters always seem to be the bigger ones\n",
    "# grid1 = [{'n_estimators' = [np.arange(0, 50, 1)],\n",
    "#          'max_features' = ['none', 'all', np.arange(0,1,0.05)]}]\n",
    "\n",
    "grid1 = [{'max_features' : ['auto', 'sqrt', 'log2', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "gridcv1 = GridSearchCV(estimator=model1, param_grid=grid1, return_train_score=True)\n",
    "gridcv1.fit(X_train, y_train)\n",
    "print(gridcv1.best_score_)\n",
    "print(gridcv1.best_estimator_.max_features)\n",
    "\n",
    "# gridcv1.best_estimator_.max_features = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.1,1.0,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.49seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9760232833923421"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time3 = time.time()\n",
    "clf3 = RandomForestClassifier(max_features = gridcv1.best_estimator_.max_features, \n",
    "                              random_state=0)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "time3 = str(round(time.time() - start_time3, 2))\n",
    "\n",
    "print(time3 + \" seconds\")\n",
    "\n",
    "# cross validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(clf3, X_train, y_train, cv=10).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1_pred = clf1.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance\n",
    "\n",
    "ROC/AUC, confusion matrix, precision vs. recall, speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10999471179270227 0.13802221047065044\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Times\n",
    "\n",
    "# false-positive, true-positive\n",
    "print(np.mean((y_test == 1) & (clf1_pred == 1)), #tpr\n",
    "      np.mean((y_test == 1) & (clf1_pred == 0))) #fpr\n",
    "\n",
    "# Precision vs. recall\n",
    "\n",
    "# Confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
