{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4: Build your own spam filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use smaller dataset to play with\n",
    "emailsplit = emails.copy()\n",
    "# emailsplit = emailsplit.loc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# words are already lemmatized, so we just remove punctuation\n",
    "emailsplit['text'] = emailsplit['text'].apply(lambda x: re.sub(r'[^\\w\\s]','',x)) # remove punctuation with regex\n",
    "\n",
    "# create cached object of stopwords to improve speed\n",
    "cachedStopwords = set(stopwords.words('english'))\n",
    "\n",
    "# remove stop words\n",
    "emailsplit['text'] = emailsplit.apply(lambda x: [item for item in x if item not in cachedStopwords])\n",
    "emailsplit['text'] = emailsplit['text'].str[8:] # remove \"subject\" from beginning of each email\n",
    "\n",
    "# remove numbers (alternatively, could convert to a single constant like a punctuation symbol to preserve some info)\n",
    "# emailsplit['text'] = emailsplit['text'].apply(lambda x: [item for item in x if item not in set())])\n",
    "\n",
    "#========================================\n",
    "# NOTES:\n",
    "# create one preprocessing function where we can choose what processing to do. Easier to check how it affects results.\n",
    "# does feature_extraction already do the above? may be redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bag of words and tf-idf sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "corpus = [] # list of email content, where each item in list is an email\n",
    "for i in range(len(emailsplit['text'])):\n",
    "    corpus.append(emailsplit.loc[i]['text'])\n",
    "    \n",
    "vectorizer = CountVectorizer() # create vectorizer\n",
    "\n",
    "wordmatrix = vectorizer.fit_transform(corpus) # sparse matrix where each value ij is how many times the word j occurs in email i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF (term frequency-inverse document frequency), a weighting scheme for words.\n",
    "# The weight increases when a word occurs many times in a small number of documents, leading to increased discriminatory power of the word. \n",
    "# The weight decreases when the word occurrs infrequently, or occurs in a large number of documents. \n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(wordmatrix) # create transformer based on vocab in train set\n",
    "tfidf = tfidf_transformer.transform(wordmatrix) # calculate tf-idf of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra variables\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# # punctuation count\n",
    "# punct = set(string.punctuation)\n",
    "# count_punct = lambda l1: sum([1 for x in l1 if x in punct])\n",
    "# emailsplit = emailsplit.assign(punct = emails['text'].apply(count_punct))\n",
    "\n",
    "# # message length\n",
    "# emailsplit = emailsplit.assign(length = emails['text'].apply(len))\n",
    "\n",
    "# count dollar sign punctuation\n",
    "count_dollar = lambda l1: sum([1 for x in l1 if x in set('$')])\n",
    "emailsplit = emailsplit.assign(dollar = emails['text'].apply(count_dollar))\n",
    "\n",
    "tfidf_ex = hstack((tfidf ,np.array(emailsplit[['dollar']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ex = tfidf_ex.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ex, emailsplit['spam'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801928590044305\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "# Tuning n_estimators\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alphas = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "model3 = MultinomialNB()\n",
    "grid3 = GridSearchCV(estimator=model3, param_grid=dict(alpha=alphas), return_train_score=True)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(grid3.best_score_)\n",
    "print(grid3.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9856648303013349"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time1 = time.time()\n",
    "\n",
    "clf1 = MultinomialNB(alpha=grid3.best_estimator_.alpha)\n",
    "# train model\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "time1 = str(round(time.time() - start_time1, 2))\n",
    "print(time1 + \" seconds\")\n",
    "\n",
    "cross_val_score(clf1, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9927026322647902\n",
      "1.0\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# Tuning C and tol\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "grid2 = [{'C': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "         'tol': [0.0001, 0.001, 0.01, 0.1, 1.0]}]\n",
    "model2 = LinearSVC()\n",
    "gridcv2 = GridSearchCV(estimator=model2, param_grid=grid2, return_train_score=True)\n",
    "gridcv2.fit(X_train, y_train)\n",
    "print(gridcv2.best_score_)\n",
    "print(gridcv2.best_estimator_.C)\n",
    "print(gridcv2.best_estimator_.tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9937425171379969"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time2 = time.time()\n",
    "\n",
    "clf2 = LinearSVC(C=gridcv2.best_estimator_.C, \n",
    "                 tol=gridcv2.best_estimator_.tol,\n",
    "                 random_state=0)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "time2 = str(round(time.time() - start_time2, 2))\n",
    "print(time2 + \" seconds\")\n",
    "\n",
    "# cross validation\n",
    "cross_val_score(clf2, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981075414030847\n",
      "log2\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Tuning for n_estimators\n",
    "# n_estimators = np.array(np.arange(50,70,1)) # the optimal parameters always seem to be the bigger ones\n",
    "# grid1 = [{'n_estimators' = [np.arange(0, 50, 1)],\n",
    "#          'max_features' = ['none', 'all', np.arange(0,1,0.05)]}]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "grid1 = [{'max_features' : ['auto', 'sqrt', 'log2', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "gridcv1 = GridSearchCV(estimator=model1, param_grid=grid1, scoring='precision', return_train_score=True)\n",
    "gridcv1.fit(X_train, y_train)\n",
    "print(gridcv1.best_score_)\n",
    "print(gridcv1.best_estimator_.max_features)\n",
    "\n",
    "# gridcv1.best_estimator_.max_features = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.902530588428108"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time3 = time.time()\n",
    "clf3 = RandomForestClassifier(max_features = gridcv1.best_estimator_.max_features, \n",
    "                              random_state=0)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "time3 = str(round(time.time() - start_time3, 2))\n",
    "\n",
    "print(time3 + \" seconds\")\n",
    "\n",
    "# cross validation\n",
    "cross_val_score(clf3, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# tuning C, the inverse of the regularization parameter\n",
    "from sklearn import linear_model\n",
    "\n",
    "# create validation training set\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33)\n",
    "\n",
    "grid4 = [{'C' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10,100,1000,10000]}]\n",
    "\n",
    "model4 = linear_model.LogisticRegression()\n",
    "gridcv4 = GridSearchCV(estimator=model4, param_grid=grid4, scoring='precision', return_train_score=True)\n",
    "gridcv4.fit(X_train, y_train)\n",
    "print(gridcv4.best_score_)\n",
    "print(gridcv4.best_estimator_.C)\n",
    "\n",
    "# gridcv1.best_estimator_.max_features = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9937445534230782"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time4 = time.time()\n",
    "clf4 = linear_model.LogisticRegression(C = gridcv4.best_estimator_.C, random_state=0)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "time4 = str(round(time.time() - start_time4, 2))\n",
    "\n",
    "print(time3 + \" seconds\")\n",
    "\n",
    "# cross validation\n",
    "cross_val_score(clf4, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "compute_rmse\n",
    "\n",
    "Given two arrays, one of actual values and one of predicted values,\n",
    "compute the Roote Mean Squared Error\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "predictions : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "yvalues : array\n",
    "    Array of numerical values corresponding to the actual values for each of the N observations\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Root Mean Squared Error of the prediction\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print compute_rmse((2,2,3),(0,2,6)\n",
    "2.08\n",
    "\"\"\"\n",
    "def compute_rmse(predictions, yvalues):\n",
    "    sigma = np.sum(np.square(np.array(predictions)-np.array(yvalues)))\n",
    "#     count = 0\n",
    "#     while count < len(preds):\n",
    "#         dif = (predictions[count] - yvalues[count])**2\n",
    "#         sigma = sigma + dif\n",
    "#         count = count + 1\n",
    "    rmse = np.sqrt(sigma/len (predictions))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13408916739344995"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1_pred = clf1.predict(X_test)\n",
    "compute_rmse(clf1_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09481535954756656"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2_pred = clf2.predict(X_test)\n",
    "compute_rmse(clf2_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16741415315900915"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3_pred = clf3.predict(X_test)\n",
    "compute_rmse(clf3_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08604353675213787"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4_pred = clf4.predict(X_test)\n",
    "compute_rmse(clf4_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance\n",
    "\n",
    "ROC/AUC, confusion matrix, precision vs. recall, speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1.03 3.55\n",
      "Naive Bayes: False Positive vs True Positive\n",
      "0.22157588577472237 0.01269169751454257\n",
      "\n",
      "Support Vector Machine: False Positive vs True Positive\n",
      "0.2316234796404019 0.0026441036488630354\n",
      "\n",
      "Random Forest: False Positive vs True Positive\n",
      "0.2316234796404019 0.0026441036488630354\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.221576</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.231623</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.213644</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FPR       TPR model\n",
       "0  0.012692  0.221576    NB\n",
       "1  0.002644  0.231623   SVM\n",
       "2  0.020624  0.213644    RF"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Times\n",
    "print(time1, time2, time3, time4)\n",
    "\n",
    "# ROC plot of different methods\n",
    "# plot TPR vs FPR\n",
    "rocdf = {'model':['NB','SVM','RF', 'Log'], \n",
    "         'TPR':[np.mean((y_test == 1) & (clf1_pred == 1)), \n",
    "                np.mean((y_test == 1) & (clf2_pred == 1)), \n",
    "               np.mean((y_test == 1) & (clf3_pred == 1)),\n",
    "               np.mean((y_test == 1) & (clf4_pred == 1))],\n",
    "        'FPR':[np.mean((y_test == 1) & (clf1_pred == 0)),\n",
    "              np.mean((y_test == 1) & (clf2_pred == 0)),\n",
    "              np.mean((y_test == 1) & (clf3_pred == 0)),\n",
    "              np.mean((y_test == 1) & (clf3_pred == 0))],\n",
    "        'Time':[time1, time2, time3, time4],\n",
    "        'RMSE':[compute_rmse(clf1_pred, y_test),\n",
    "               compute_rmse(clf2_pred, y_test),\n",
    "               compute_rmse(clf3_pred, y_test),\n",
    "               compute_rmse(clf4_pred, y_test)]}\n",
    "\n",
    "rocdf = pd.DataFrame(rocdf)\n",
    "rocdf\n",
    "\n",
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200b0af0358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(rocdf['FPR'],rocdf['TPR'])\n",
    "\n",
    "def specificity(y_test, clf_pred):\n",
    "    spec = np.sum((y_test == 0) & (clf_pred == 0)) / (np.sum((y_test == 0) & (clf_pred == 0)) + np.sum((y_test == 0) & (clf_pred == 1)))\n",
    "    return spec\n",
    "\n",
    "def sensitivity(y_test, clf_pred):\n",
    "    sens = np.sum((y_test == 1) & (clf_pred == 1)) / (np.sum((y_test == 1) & (clf_pred == 1)) + np.sum((y_test == 1) & (clf_pred == 0)))\n",
    "    return sens\n",
    "\n",
    "specificity(y_test, clf1_pred)\n",
    "specificity(y_test, clf2_pred)\n",
    "specificity(y_test, clf3_pred)\n",
    "\n",
    "sensitivity(y_test, clf1_pred)\n",
    "sensitivity(y_test, clf2_pred)\n",
    "sensitivity(y_test, clf3_pred)\n",
    "\n",
    "rocdf = {'model':['NB','SVM','RF'], \n",
    "         'FPR':[1-specificity(y_test, clf1_pred),\n",
    "                1-specificity(y_test, clf2_pred),\n",
    "                1-specificity(y_test, clf3_pred),],\n",
    "        'TPR':[sensitivity(y_test, clf1_pred),\n",
    "              sensitivity(y_test, clf2_pred),\n",
    "              sensitivity(y_test, clf3_pred)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
